{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h1 align=\"left\">**Inferential Statistics** </h1>\n",
    "<br>\n",
    "<img src=\"../images/inferential.gif\" alt=\"Python\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda for the Day\n",
    "***\n",
    "- Basic Probability\n",
    "- Condition Probability\n",
    "- Normal Distribution\n",
    "- Central Limit Theorem\n",
    "- Hypothesis Testing\n",
    "- P-value and Confidence Interval\n",
    "- Type I and Type II error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's Still Searching \n",
    "***\n",
    "- Well, buying a house is no joke. There are a number of factors that need to be considered while selecting 1 particular house\n",
    "\n",
    "\n",
    "- One such factor is Neighborhood!\n",
    "\n",
    "\n",
    "- Yesterday, we learnt that Brooklyn is 1 of 5 'boroughs' in New York\n",
    "\n",
    "\n",
    "- But it has several neighborhoods. Interestingly, like any big city, some are rich, some are poor, some are in the process of being gentrified, some are culturally diverse, etc. \n",
    "\n",
    "\n",
    "- John has displayed interest in several such neighborhoods and in addition to his 1460 observations, he found out the neighborhood of each and everyone of them! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## John's Curiosity\n",
    "***\n",
    "- By just looking at the data, John sees interesting house prices in a neighborhood called \"OldTown\"\n",
    "\n",
    "- He's curious about this Neighborhood and want's to see, for his own amusement, that if one was to pick a house at random, what were the chances that the house would be in OldTown\n",
    "\n",
    "\n",
    "- Now, this is all a part of Basic Probability. Let's try and build our intuition on this first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Probability - Intuition\n",
    "***\n",
    "\n",
    " - Let's start with a simple example: Say, we flip a fair coin\n",
    " \n",
    " - Intuitively, there's a 50% chance of getting heads, and a 50% chance of getting tails. This is because there are only two possible outcomes, and each event is equally likely.\n",
    " \n",
    " - Therefore, we can say that the **Probability** of getting a *Heads* is 0.5. Similarly, Probability of getting a *Tails* is 0.5 \n",
    " \n",
    " - **Probability can roughly be described as \"the percentage chance of an event or sequence of events occurring\".**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Probability - Intuition\n",
    "\n",
    "Some common terms thrown around are: \n",
    "\n",
    "* **Experiment** – are the uncertain situations, which could have multiple outcomes. A coin toss is an experiment.\n",
    "* **Outcome** is the result of a single trial. So, if head lands, the outcome of or coin toss experiment is “Heads”\n",
    "* **Event** is one or more outcomes from an experiment. “Tails” is one of the possible events for this experiment.\n",
    "***\n",
    "<center><img src=\"../images/Probability.PNG\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Get it? \n",
    "***\n",
    "<center><img src=\"../images/meme_jim.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Probability - Easy Rules\n",
    "***\n",
    "These are a list of some comprehensive rules Probability must follow: \n",
    "\n",
    " - The Probability that nothing occurs is 0 \n",
    " - The Probability that something occurs is 1\n",
    " - The probability of something is 1 minus the probability that the opposite occurs\n",
    " \n",
    " - The probability of at least 1 of 2 (or more) things that can not simultaneously occur (mutually exclusive) is the sum of their respective probabilities\n",
    " \n",
    " - **\"Mutually exclusive\"** is a statistical term describing two or more events that cannot occur simultaneously. For example, it is impossible to roll a five and a three on a single die at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Probability - Easy Rules\n",
    "***\n",
    " - For any 2 events the probability that at least one occurs is the sum of their probabilities minus their intersection\n",
    " \n",
    " **In-class Activity** \n",
    " \n",
    " - The National Sleep Foundation reports that around 3% of the American population has sleep-breathing issues. They also report that around 10% of the American population has *restless leg syndrome*. Does this imply that 13% of people will have at least one sleep problems of these sorts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Answer: No, the events can simultaneously occur and so are not mutually exclusive. To elaborate let:\n",
    "\n",
    "$ \\begin{eqnarray*} A_1 & = & {\\mbox{Person has sleep apnea}} \\ A_2 & = & {\\mbox{Person has RLS}} \\end{eqnarray*} $\n",
    "\n",
    "Then\n",
    "\n",
    "$ \\begin{eqnarray*} P(A_1 \\cup A_2 ) & = & P(A_1) + P(A_2) - P(A_1 \\cap A_2) \\ & = & 0.13 - \\mbox{Probability of having both} \\end{eqnarray*} $\n",
    "\n",
    "Given the scenario, it's likely that some fraction of the population has both. This example serves as a reminder don't add probabilities unless the events are mutually exclusive. We'll have a similar rule for multiplying probabilities and independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming back to John\n",
    "***\n",
    "- Now John is wants to check the Probability of picking a house in \"OldTown\"\n",
    "\n",
    "- This is nothing but: \n",
    "   - No. of houses in OldTown/Total no. of houses\n",
    "   \n",
    "- Let's go through this in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9442515869d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Neighborhood'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'OldTown'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data[data['Neighborhood'] == 'OldTown'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../train.csv\")\n",
    "\n",
    "all_houses = data.shape[0]\n",
    "houses_in_OldTown = data[data['Neighborhood'] == 'OldTown'].shape[0]\n",
    "print('Probability of picking a house in OldTown: {}'.format(houses_in_OldTown/all_houses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, from the output above we can state that: \n",
    "\n",
    "At random, the probability of choosing a house from the data set in the \"OldTown\" neighborhood is *0.077*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What if John was extra curious? \n",
    "***\n",
    "\n",
    "- Having found out the probability of picking a house from the \"OldTown\" neighborhood, what if John wanted to go further? \n",
    "\n",
    "\n",
    "- Even though this would be pretty redundant, but when picking **1 by 1**, what would be the probability of first picking a house from the \"OldTown\" neighborhood and then **AGAIN** picking a house from the **SAME** neighborhood? \n",
    "\n",
    "\n",
    "- This is nothing but Conditional Probability!\n",
    "\n",
    "- This might sound a little complicated at first but let's break it down by starting with an easy example! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Conditional Probability - Intuition (1/2)\n",
    "***\n",
    "Let's say that we're eating some M&Ms. \n",
    "\n",
    " - There are 10 GEMS left in the bag: 5 are green, and 5 are blue.\n",
    " \n",
    " - What is the probability of getting 3 blue candies in a row? \n",
    "     - The probability of getting the first blue candy is 5/10, or 1/2. \n",
    "     - When we pick a blue candy, though, we remove it from the bag. We're left with **9** candies in total with (5-1 =)4 Blue ones.\n",
    "     - So the probability of getting another blue is 4/9. \n",
    "     - Similarly, the probability of picking a third blue candy is 3/8\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Conditional Probability - Intuition (2/2)\n",
    "***\n",
    "- Since we're calculating the probability of picking 1 Blue Candy AND 1 Blue Candy AND 1 Blue Candy\n",
    "\n",
    "    - Our final probability is 1/2 \\* 4/9 \\* 3/8, or .0833. So, there is an 8.3% chance of picking three blue candies in a row.\n",
    "    \n",
    "    \n",
    "- **Simple tricks**: Whenever you have to *verbally* say AND (like we just did above), you will want to **MULTIPLY** the probabilities\n",
    "\n",
    "\n",
    "- Whenever you have to *verbally* say OR, you will want to **ADD** the probabilities. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In-class Activity - Can you solve this on your own? \n",
    "***\n",
    "1) What is the probability of picking a green candy OR a blue candy?\n",
    "\n",
    "2) Consider we have 7 green candies and 5 blue candies. What is the probability of picking (one by one, and without replacing) 2 green candies OR 2 blue candies? \n",
    "\n",
    "Answers : \n",
    "\n",
    "1) $(5/10)+(5/10)=1$\n",
    "\n",
    "2) $(7/12)*(6/11)+(5/12)*(4/11)=(62/132)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Probability\n",
    "***\n",
    "To summarize, **Conditional probability is the probability of an  event A occurring, given that B has already occurred.**\n",
    "\n",
    "- It is also denoted by:\n",
    "***\n",
    "<center><img src=\"../images/CP_1.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Probability\n",
    "***\n",
    "Coming back to John: \n",
    "\n",
    " - What would be the probability of first picking a house from the \"OldTown\" neighborhood and then **AGAIN** picking a house from the **SAME** neighborhood?\n",
    " \n",
    " - Let's find this out in Python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Enter condtional probability code\n",
    "(houses_in_OldTown/all_houses) * ((houses_in_OldTown - 1)/(all_houses - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some Basic Concepts \n",
    "***\n",
    " - Before moving on to other questions John asked let's try and understand some basic concepts\n",
    " \n",
    " - We know what the outcome of an experiment is. \n",
    " \n",
    " - Now, depending on the experiment, our outcome can have a range of possible values \n",
    " \n",
    " - Each value has a specific, probability assigned to it. These probabilities may or may not be equal to one another\n",
    " \n",
    " - Now, like always, there is a Statistical Function that describes these values within a given range\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Basic Concepts\n",
    "***\n",
    " - This is nothing but the Probability Distribution of the event\n",
    " \n",
    " - Confused? You're not the first..\n",
    " \n",
    " - Let's try and build some intuition with an easy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple Probability Distribution\n",
    "***\n",
    " -  Lets try and plot a simple probability distribution\n",
    " \n",
    " - Let a random variable X be the sum of two fair six sided dice throws\n",
    " \n",
    " - X can take values (2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n",
    " \n",
    " - Can you figure our the proability of each value of X? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Maths-Insight.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "## Simple Probability Distribution\n",
    "***\n",
    "- There are 6 possibilities in the first throw (we can get any number). We can get any no. from 1 to 6 \n",
    "\n",
    "- 6 in the second\n",
    "\n",
    "- Total no. of Combinations = 6\\*6 = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s see how:\n",
    "2{(1,1)}  => 1/36\n",
    "\n",
    "3{(1,2),(2,1)} => 2/36\n",
    "\n",
    "4{(2,2),(3,1),(1,3)} => 3/36\n",
    "\n",
    "5{(1,4),(4,1),(2,3),(3,2)} => 4/36\n",
    "\n",
    "6{(3,3),(1,5),(5,1),(2,4),(4,2)} => 5/36\n",
    "\n",
    "7{(1,6),(6,1),(2,5),(5,2),(3,4),(4,3)} => 6/36\n",
    "\n",
    "8{(2,6),(6,2),(3,5),(5,3),(4,4)} => 5/36\n",
    "\n",
    "9{(3,6),(6,3),(5,4),(4,5)} => 4/36\n",
    "\n",
    "10{(4,6),(6,4),(5,5)} => 3/36\n",
    "\n",
    "11{(5,6),(6,5)} => 2/36\n",
    "\n",
    "12{(6,6)} = > 1/36\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting our results\n",
    "When we plot the values [2,12] on the x-axis vs. the probability of getting each of these values as our Outcome we see the following: \n",
    "***\n",
    "<center><img src=\"../images/Prob_dist.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In Case You Forgot (1/2)\n",
    "***\n",
    " - A **discrete variable** is a variable whose value is obtained by counting\n",
    "    - Examples:  number of students present, number of red marbles in a jar, number of heads when flipping three coins\n",
    "    \n",
    " \n",
    " - A **continuous variable** is a variable whose value is obtained by measuring\n",
    "    - Examples: height of students in class, weight of students in class, time it takes to get to school, distance traveled between classes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In Case You Forgot (2/2)\n",
    "***\n",
    "\n",
    "- The probability function for a discrete random variable is the **`probability mass function`** and similarly if our random variable takes continuous values it is called a **`probability density function`**\n",
    " \n",
    " \n",
    " - Can you guess what we just plotted in the previous slide? \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Basic Concepts\n",
    "***\n",
    " - In the previous few slides we plotted the Probability Mass Function of a Discrete Random Variable (X which is the sum of two fair dies)\n",
    " \n",
    " - One of the most common Probability Distribution Functions is the Normal Distribution.\n",
    " \n",
    " - Let's learn some basic concepts on the Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Normal Distribution (1/4)\n",
    "***\n",
    " - Data can be \"distributed\" (spread out) in different ways\n",
    "***\n",
    "<center><img src=\"../images/norm1.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Normal Distribution (2/4)\n",
    "***\n",
    " - But there are many cases where the data tends to be around a central value with no bias left or right, and it gets close to a \"Normal Distribution\" like this:\n",
    "***\n",
    "<center><img src=\"../images/norm2.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Normal Distribution (3/4)\n",
    "***\n",
    " - It is known as a \"Bell Curve\" because it literally looks like a bell\n",
    " \n",
    " - Many things closely follow a Normal Distribution:\n",
    "    - heights of people\n",
    "    - size of things produced by machines\n",
    "    - errors in measurements\n",
    "    - blood pressure\n",
    "    - marks on a test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Normal Distribution (4/4)\n",
    "***\n",
    " - We say that the data is \"Normally Distributed\" \n",
    " \n",
    " - The Normal Distribution has:\n",
    "    - mean = median = mode\n",
    "    - symmetry about the center\n",
    "    - 50% of values less than the mean \n",
    "    - and 50% greater than the mean\n",
    "    - The total area under the curve is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Normal Distribution\n",
    "***\n",
    "\n",
    "<center><img src=\"../images/norm3.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normal Distributions and Standard Deviations\n",
    "***\n",
    " - Yesterday we learnt about Standard Deviation and how it's the most commonly used measure of how spread out observations of our data are\n",
    " \n",
    " - When we calculate the standard deviation we find that (generally):\n",
    " \n",
    "    - 68% of values are within 1 standard deviation\tof the mean\n",
    "    - 95% of values are within 2 standard deviations of the mean\n",
    "    - 99.7% of values are within 3 standard deviations of the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Normal distribution](../images/normal_distribution_0.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Maths-Insight.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Math behind the Normal Distribution\n",
    "***\n",
    "- So how do we get a Bell Curve? \n",
    "- As discussed before, there is a Statistical Function that describes it's shape, just like any other graph in Mathematics\n",
    "\n",
    " ***\n",
    "<center><img src=\"../images/norm4.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Looking at John's Data \n",
    "***\n",
    " - We know that John had the SalePrice data of the 1460 houses in Brooklyn\n",
    " \n",
    " - Let's plot a graph that shows us the SalePrice vs. the Frequency of that Price\n",
    " \n",
    " - Work it out in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.xticks(rotation=30)\n",
    "sns.distplot(data['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thoughts \n",
    "***\n",
    "The distribution is for our target variable aka SalePrice doesn't resemble a normal distribution, it is skewed to the left\n",
    "\n",
    " - This makes some sense since we already saw yesterday that we had a lot of Outliers on the upper-end of the Price scale\n",
    " \n",
    " - If you were to remove the outliers, it'd somewhat resemble a Normal Dstribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## The Concept of Z-score (1/5)\n",
    "***\n",
    " - The number of standard deviations from the mean is also called the \"Standard Score\", \"sigma\" or \"z-score\". Get used to those words!\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "## The Concept of Z-score (2/5)\n",
    "***\n",
    "- As usual, let's build our intution with an Example\n",
    "    - Consider that we're analyzing data of the heights (in meters) of students in a school \n",
    "    - The data is normally distributed as shown below:\n",
    " ***\n",
    "<center><img src=\"../images/norm6.gif\" alt=\"Drawing\" style=\"width: 300px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## The Concept of Z-score (3/5)\n",
    "***\n",
    " - We can see that the mean = 1.4 meters\n",
    " - In that same school one of your friends is 1.85m tall\n",
    " - You can see on the bell curve that 1.85m is 3 standard deviations from the mean of 1.4, so:\n",
    " - **Your friend's height has a \"z-score\" of 3.0**\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## The Concept of Z-score (4/5)\n",
    "***\n",
    " - It is also possible to calculate how many standard deviations 1.85 is from the mean\n",
    "      - How far is 1.85 from the mean?\n",
    "      - It is 1.85 - 1.4 = 0.45m from the mean\n",
    " \n",
    " - Say that the Std. Dev. is pre-calculated and is = 0.15m\n",
    " \n",
    " - How many standard deviations is is it from the mean? The standard deviation is 0.15m, so:\n",
    "\n",
    "     - = 0.45m / 0.15m = 3 standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## The Concept of Z-score (5/5)\n",
    "***\n",
    "So to convert a value to a Standard Score (\"z-score\"):\n",
    "\n",
    " - first subtract the mean,\n",
    " - then divide by the Standard Deviation\n",
    "\n",
    "And doing that is called \"Standardizing\":\n",
    " ***\n",
    "<center><img src=\"../images/norm7.svg\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Normal Distribution with Paranormal Activity\n",
    " ***\n",
    "<center><img src=\"../images/normal_meme.png\" alt=\"Drawing\" style=\"width: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In Class Activity\n",
    "***\n",
    "Example: Travel Time\n",
    "\n",
    "A survey of daily travel time had these results (in minutes):\n",
    "\n",
    "26, 33, 65, 28, 34, 55, 25, 44, 50, 36, 26, 37, 43, 62, 35, 38, 45, 32, 28, 34\n",
    "\n",
    "Convert the values to z-scores (\"standard scores\").\n",
    "\n",
    "Don't forget:\n",
    " ***\n",
    "<center><img src=\"../images/z-score.gif\" alt=\"Drawing\" style=\"width: 100px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## John's Random Experiment (1/2)\n",
    "***\n",
    "- So John is curious to experiment with his data, again! \n",
    "\n",
    "- He somehow thinks that 1460 is a lot of houses to look at! So he needs to narrow his search down a bit\n",
    "\n",
    "- What he does is naive but he decides to just pick 500 houses at random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's Random Experiment (2/2)\n",
    "***\n",
    "\n",
    "- But then he has a feeling that these houses don't truly represent the prices and features of the houses he had selected a while ago.\n",
    "- In simple words, he thought that these houses may be either too expensive, or too cheap as compared to the 500 \n",
    "   - What he means is: The mean of the 500 houses would be pretty far away from the mean of the 1460 houses that he had calculated earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note\n",
    "***\n",
    "- We discussed that the Median would be a better measure but for the sake of simplicity of further calculations and concept-building, let's consider the Mean of all houses in the following cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's 1st Simple Test\n",
    "***\n",
    " - So John tests the mean of the 500 houses and compares it to the 1460 houses\n",
    " \n",
    " - What John has done, is nothing but build the basic concepts of Statistical Inference in himself! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "sample_ages = np.random.choice(a= data['SalePrice'], size=500) # Sample 500 values\n",
    "print (\"Sample mean:\", sample_ages.mean() )                         # Show sample mean\n",
    "print(\"Population mean:\", data['SalePrice'].mean())  # Show population mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Inference\n",
    "***\n",
    " - Let's try and understand the words \"Sample\" & \"Population\" as these will be used a lot in Statistics\n",
    " \n",
    " - Again, let's build our intuition with the help of some easy examples \n",
    " \n",
    " \n",
    " - While analyzing data with statistical thinking, we are often interested in the characteristics of some large population\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***\n",
    "## Statistical Inference\n",
    "***\n",
    "\n",
    "But **collecting data on the entire population may be infeasible**\n",
    " \n",
    "- For example, leading up to U.S. presidential elections it could be very useful to know the political leanings of every single eligible voter, but surveying every voter is not feasible.\n",
    "\n",
    "- Instead, we could poll some subset of the population, such as a thousand registered voters, and use that data to make inferences about the population as a whole.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Inference\n",
    "***\n",
    " - This *\"subset\"* of the population is nothing but the **Sample** data \n",
    " \n",
    " - We carry out various tests on the Sample to gain insight on the larger population out there! \n",
    " \n",
    " - Therefore Statistical inference is the process of analyzing sample data to gain insight into the population from which the data was collected and to investigate differences between data samples.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Statistical Inference\n",
    "***\n",
    "- In John's case, he is primarily concerned with the SalePrice of every house in Brooklyn \n",
    "    - Therefore, it's safe to assume that John's 1460 house prices is a **Sample** of the data \n",
    "    - The Population would be the price of **Every** house in Brooklyn \n",
    "    \n",
    "\n",
    " - But since John took a subset (i.e. 500) of the data from 1460 we can assume that: \n",
    "     - The 1460 Houses are the Population for the next few examples \n",
    "     - The 500 houses are the Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Terminology: Point Estimates\n",
    "***\n",
    "Point estimates are estimates of population parameters based on sample data. \n",
    "\n",
    "* For instance, if we wanted to know the average age of registered voters in the U.S., we could take a survey of registered voters and then use the average age of the respondents as a point estimate of the average age of the population as a whole.\n",
    "\n",
    "* The sample mean is usually not exactly the same as the population mean. This difference can be caused by many factors including poor survey design, biased sampling methods and the randomness inherent to drawing a sample from a population. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Point Estimates in John's Simple Test \n",
    "***\n",
    "* John's point estimate based on a sample of 500 houses underestimates the true population mean by \\$3,400, but it is close! \n",
    "\n",
    "\n",
    "* This illustrates an important point: *we can get a fairly accurate estimate of a large population by sampling a relatively small subset of individuals*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Terminology - Parameter & Statistic \n",
    "***\n",
    "- A parameter is a descriptive measure of the population.\n",
    "    - Example: Population mean, Population variance etc.\n",
    "- A statistic is a  descriptive measure of the sample.\n",
    "    - Example: Sample mean, Sample variance etc.\n",
    "     ***\n",
    "<center><img src=\"../images/parstat.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ***\n",
    "<center><img src=\"../images/sample2.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Don't try this at home\n",
    " ***\n",
    "<center><img src=\"../images/sample.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some Basic Concepts 2.0! \n",
    "***\n",
    " - Before moving on to other 'experiments' John performed with his data, let's try and uderstand some of the most commonly used concepts in Statistics\n",
    " \n",
    " - You might have heard about the term Central Limit Theorem before\n",
    " \n",
    " - Let's understand what it means and its relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "### Central Limit Theorem  - Important! (1/2) \n",
    "***\n",
    " - The central limit theorem (CLT) is a statistical theory that states that given a sufficiently large sample size from a population with a finite level of variance, the `mean` of all samples means from the same population will be approximately equal to the `mean` of the population. Furthermore, all of the samples will follow an approximate normal distribution pattern, with all variances being approximately equal to the variance of the population divided by each sample's size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "### Central Limit Theorem  - Important! (2/2)\n",
    "***\n",
    "- According to the central limit theorem, the mean of a sample of data will be closer to the mean of the overall population in question as the sample size increases, notwithstanding the actual distribution of the data, and whether it is normal or non-normal. As a general rule, sample sizes equal 30 ~ 40  are considered sufficient for the central limit theorem to hold (if the underlying popoulation is highly skew take little larger sample meaning greater than 40), meaning the distribution of the sample means is fairly normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Video on the CLT\n",
    "***\n",
    "- This is a very nice and intuitive video on the CLT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/JNm3M9cqWyc\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Central Limit Theorem - Important (1/2)\n",
    "***\n",
    "* Many practices in statistics, such as those involving hypothesis testing or confidence intervals, make some assumptions concerning the population that the data was obtained from.\n",
    "\n",
    "* One assumption that is initially made in a statistics course is that the populations that we work with are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/icon/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br /> \n",
    "\n",
    "## Central Limit Theorem - Important (2/2)\n",
    "***\n",
    "\n",
    "* The assumption that data is from a normal distribution simplifies matters but seems a little unrealistic.\n",
    "\n",
    "* Just a little work with some real-world data shows that outliers, skewness, multiple peaks and asymmetry show up quite routinely like the one John encountered with `SalePrice` above.\n",
    "\n",
    "* We can get around the problem of data from a population that is not normal. \n",
    "\n",
    "* The use of an appropriate sample size and the central limit theorem help us to get around the problem of data from populations that are not normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # provides capability to define function with partial arguments\n",
    "\n",
    "N=1000 # number of times n samples are taken. Try varying this number.\n",
    "nobb=101 # number of bin boundaries on plots\n",
    "n=np.array([1,2,3,5,10,100, 200]) # number of samples to average over\n",
    "\n",
    "exp_mean=3 # mean of exponential distribution\n",
    "a,b=0.7,0.5 # parameters of beta distribution\n",
    "\n",
    "dist=[partial(np.random.random),partial(np.random.exponential,exp_mean),partial(np.random.beta,a,b)]\n",
    "title_names=[\"Flat\", \"Exponential (mean=%.1f)\" % exp_mean, \"Beta (a=%.1f, b=%.1f)\" % (a,b)]\n",
    "drange=np.array([[0,1],[0,10],[0,1]]) # ranges of distributions\n",
    "means=np.array([0.5,exp_mean,a/(a+b)]) # means of distributions\n",
    "var=np.array([1/12,exp_mean**2,a*b/((a+b+1)*(a+b)**2)]) # variances of distributions\n",
    "\n",
    "binrange=np.array([np.linspace(p,q,nobb) for p,q in drange])\n",
    "ln,ld=len(n),len(dist)\n",
    "plt.figure(figsize=((ld*4)+1,(ln*2)+1))\n",
    "\n",
    "for i in range(ln): # loop over number of n samples to average over\n",
    "    for j in range(ld): # loop over the different distributions\n",
    "        plt.subplot(ln,ld,i*ld+1+j)\n",
    "        plt.hist(np.mean(dist[j]((N,n[i])),1),binrange[j],normed=True)\n",
    "        plt.xlim(drange[j])\n",
    "        if j==0:\n",
    "            plt.ylabel('n=%i' % n[i],fontsize=15)        \n",
    "        if i==0:\n",
    "            plt.title(title_names[j], fontsize=15)\n",
    "        else:\n",
    "            clt=(1/(np.sqrt(2*np.pi*var[j]/n[i])))*np.exp(-(((binrange[j]-means[j])**2)*n[i]/(2*var[j])))\n",
    "            plt.plot(binrange[j],clt,'y',linewidth=2)     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the graphs above the yellow curve is the predicted Gaussian distribution from the Central Limit Thereom. Notice that the rate of convergence of the sample mean to the Gaussian depends on the original parent distribution. Also, \n",
    "\n",
    "- the mean of the Gaussian distribution is the same as the original parent distribution,\n",
    "- the width of the Gaussian distribution scales as $1/\\sqrt{n}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In Class Activity\n",
    "***\n",
    "In order to understand the Central Limit Theorem and understand why distribution of  sample means is normally distributed, try tinkering around the below shiny app. Change the Parent Distribution, sample size and no of samples and see how CLT helps us make inferences about the population statistics even when the population isn't normal.\n",
    "\n",
    "\n",
    "https://gallery.shinyapps.io/CLT_mean/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## John's Second Experiment \n",
    "***\n",
    " - Now John wants to test that if he takes 1000 houses, instead of 500, will those houses contain the Population (1460 Houses) mean too? \n",
    " \n",
    " - He thinks that it might not contain the Population mean and if so, he'll have to take another sample of 1000. So how many times would he have to do this? \n",
    " \n",
    " - Thanks to programming, it's easy to take many samples. But he want's to be confident that the Population Mean is contained in his samples, majority of the times. \n",
    " \n",
    " - Confused? That's ok. John basically wants to check the confidence interval of the Mean of his many samples of 1000 houses! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Confidence Intervals  (1/4)\n",
    "***\n",
    " - A Confidence Interval is a range of values we are fairly sure our true value lies in! \n",
    " \n",
    " - That's basically the simplest but true explanation of Confidence Interval\n",
    "     ***\n",
    "<center><img src=\"../images/ci1.gif\" alt=\"Drawing\" style=\"width: 200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence Intervals (2/4)\n",
    "***\n",
    " - Let's build our intuition with the help of an example\n",
    " \n",
    " - Example: Average Height\n",
    "\n",
    "    - We measure the heights of 40 randomly chosen men, and get a:\n",
    "\n",
    "            - mean height of 175cm,\n",
    "            - with a standard deviation of 20cm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence Intervals (3/4)\n",
    "***\n",
    " - The 95% Confidence Interval (we will learn how to calculate this later) is:\n",
    " ***\n",
    " <center><img src=\"../images/ci2.gif\" alt=\"Drawing\" style=\"width: 200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence Intervals (4/4)\n",
    "***\n",
    "- This says the true mean of ALL men (if we could measure their heights) is likely to be between 168.8cm and 181.2cm.\n",
    "\n",
    "- But it might not be!\n",
    "\n",
    "- The \"95%\" says that 95% of experiments like we just did will include the true mean, but 5% won't.\n",
    "\n",
    "- So there is a 1-in-20 chance (5%) that our Confidence Interval does NOT include the true mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Calculating the Confidence Interval (1/3)\n",
    "***\n",
    "Step 1: note down the number of samples n, and calculate the mean X and standard deviation s of those samples:\n",
    "\n",
    " - Number of samples: n = 40\n",
    " - Mean: X_bar = 175\n",
    " - Standard Deviation: s = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Calculating the Confidence Interval (2/3)\n",
    "***\n",
    "Step 2: decide what Confidence Interval we want. 90%, 95% and 99% are common choices. Then find the \"Z\" value for that Confidence Interval here:\n",
    " ***\n",
    " <center><img src=\"../images/ci3.png\" alt=\"Drawing\" style=\"width: 200px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating the Confidence Interval (3/3)\n",
    "***\n",
    "For 95% the Z value is 1.960\n",
    "\n",
    "Step 3: use that Z in this formula for the Confidence Interval\n",
    " ***\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ {\\bar{X}} { ± } {Z}\\frac{{s}}{\\sqrt{n}} $      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thus, we have: \n",
    "    \n",
    "    175 ± 1.960\\*(20/sqrt(40))\n",
    "    \n",
    "    = 175cm ± 6.2cm\n",
    "    \n",
    "In other words: from 168.8cm to 181.2cm\n",
    "\n",
    " - The value after the ± is called the **margin of error**\n",
    " - The **margin of error** in the previous example is 6.20cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of Confidence Intervals\n",
    "***\n",
    "Let's build our intution, again, with the help of an example. This should help explain how to interpret the Confidence Interval\n",
    "\n",
    "Example: Apple Orchard\n",
    "\n",
    " - Are the apples big enough?\n",
    "\n",
    " - There are hundreds of apples on the trees, so you randomly choose just 30 and get these results:\n",
    "\n",
    "    - Mean: 86\n",
    "    - Standard Deviation: 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of Confidence Intervals\n",
    "***\n",
    "We know:\n",
    "\n",
    " - X is the mean = 86\n",
    " - Z is the Z-value = 1.960 (from the table above for 95%)\n",
    " - s is the standard deviation = 5\n",
    " - n is the number of samples = 30\n",
    " - 86  ±  1.960\t5\t = 86 ± (1.79/√30)\n",
    "\n",
    "\n",
    "So the true mean (of all the hundreds of apples) is likely to be between 84.21 and 87.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of Confidence Intervals\n",
    "***\n",
    "True Mean\n",
    "\n",
    "Now imagine we get to pick ALL the apples straight away, and get them ALL measured by the packing machine (this is a luxury not normally found in statistics!)\n",
    "\n",
    "And the true mean turns out to be 84.9\n",
    "\n",
    "Let's lay all the apples on the ground from smallest to largest:\n",
    "\n",
    " - Each apple is a green dot, except our samples which are blue\n",
    " ***\n",
    " <center><img src=\"../images/ci5.gif\" alt=\"Drawing\" style=\"width: 200px;\"/></center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of Confidence Intervals\n",
    "***\n",
    " - Our result was not exact ... it is random after all ... but the true mean is inside our confidence interval of 86 ± 1.79 (in other words 84.21 to 87.79) \n",
    " \n",
    " - But the true mean might not be inside the confidence interval but 95% of the time it will!\n",
    " \n",
    "  ### 95% of all \"95% Confidence Intervals\" will include the true mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of Confidence Intervals (1/2)\n",
    "***\n",
    "Maybe we had this sample, with a mean of 83.5 and a Standard Deviation of 3.5:\n",
    "\n",
    " - That does not include the true mean. Expect that to happen 5% of the time for a 95% confidence interval.\n",
    "\n",
    " - So how do we know if the sample we took is one of the \"lucky\" 95% or the unlucky 5%? Unless we get to measure the whole population like above we simply don't know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of Confidence Intervals (1/2)\n",
    "***\n",
    "- *This is the risk in sampling, we might have a bad sample.* (Important!) \n",
    " \n",
    " - There are various Statistical techniques that are done to specifically address this issue (Discussion is beyond the scope of this lecture) \n",
    "\n",
    "\n",
    "***\n",
    " <center><img src=\"../images/ci5.gif\" alt=\"Drawing\" style=\"width: 200px;\"/></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We should try and keep it real but laziness..\n",
    "\n",
    "***\n",
    " <center><img src=\"../images/ci_meme.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming Back to John's Experiment \n",
    "***\n",
    " - John decides to carry out the experiment to see whether the houses do have the True Mean within the sample! \n",
    "\n",
    " - Let's get right into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "sample_size = 1000\n",
    "sample = np.random.choice(a= data['SalePrice'], size = sample_size)\n",
    "sample_mean = sample.mean()\n",
    "\n",
    "z_critical = stats.norm.ppf(q = 0.95)  # Get the z-critical value*\n",
    "\n",
    "print(\"z-critical value:\")              # Check the z-critical value\n",
    "print(z_critical)                        \n",
    "\n",
    "pop_stdev = data['SalePrice'].std()  # Get the population standard deviation\n",
    "\n",
    "margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size))\n",
    "\n",
    "confidence_interval = (sample_mean - margin_of_error,\n",
    "                       sample_mean + margin_of_error)  \n",
    "\n",
    "print(\"Confidence interval:\")\n",
    "print(confidence_interval)\n",
    "print(\"True mean: {}\".format(data['SalePrice'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Notice that the true mean is contained in our interval.\n",
    "* A confidence interval of 95% would mean that if we take many samples and create confidence intervals for each of them, 95% of our sample's confidence intervals will contain the true population mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's Experiment - Continued\n",
    "***\n",
    "* Now, instead of 1, John creates several confidence intervals and plots them to get a better sense of what it means to \"capture\" the true mean\n",
    "\n",
    "* He does this for 25 trials! \n",
    "\n",
    "* Let's check out what he got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-77e92d413943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msample_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msample_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "\n",
    "sample_size = 500\n",
    "\n",
    "intervals = []\n",
    "sample_means = []\n",
    "\n",
    "for sample in range(25):\n",
    "    sample = np.random.choice(a= data['SalePrice'], size = sample_size)\n",
    "    sample_mean = sample.mean()\n",
    "    sample_means.append(sample_mean)\n",
    "\n",
    "    z_critical = stats.norm.ppf(q = 0.975)  # Get the z-critical value*         \n",
    "\n",
    "    pop_stdev = data['SalePrice'].std()  # Get the population standard deviation\n",
    "\n",
    "    stats.norm.ppf(q = 0.025)\n",
    "\n",
    "    margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size))\n",
    "\n",
    "    confidence_interval = (sample_mean - margin_of_error,\n",
    "                           sample_mean + margin_of_error)  \n",
    "    \n",
    "    intervals.append(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-02dd92a3e4ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m plt.errorbar(x=np.arange(0.1, 25, 1), \n\u001b[0;32m      4\u001b[0m              \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_means\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m              \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mintervals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.errorbar(x=np.arange(0.1, 25, 1), \n",
    "             y=sample_means, \n",
    "             yerr=[(top-bot)/2 for top,bot in intervals],\n",
    "             fmt='o')\n",
    "\n",
    "plt.hlines(xmin=0, xmax=25,\n",
    "           y=data['SalePrice'].mean(), \n",
    "           linewidth=2.0,\n",
    "           color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Notice that in the plot above, all but one of the 95% confidence intervals overlap the red line marking the true mean. This is to be expected: since a 95% confidence interval captures the true mean 95% of the time, we'd expect our interval to miss the true mean 5% of the times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's Curiosity of OldTown \n",
    "***\n",
    " - Now, John is interested in dissecting the whole Real Estate Scene in OldTown\n",
    " \n",
    " - He's interested in seeing whether the prices of houses are different (on an average) when compared to the rest of Brooklyn \n",
    " \n",
    " - John has just conjured up what is famously known as a \"Hypothesis\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Hypothesis \n",
    "***\n",
    "A statement that might be true, which can then be tested.\n",
    "\n",
    "Example: Sam has a hypothesis that \"large dogs are better at catching tennis balls than small dogs\". We can test that hypothesis by having hundreds of different sized dogs try to catch tennis balls.\n",
    "\n",
    "- The beauty of these Hypotheses are that they can be TESTED! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Hypothesis Testing \n",
    "***\n",
    "- Statistical hypothesis tests are based a statement called the null hypothesis that assumes nothing (or related) interesting is going on between whatever variables you are testing. \n",
    " \n",
    " - Therefore, in John's case the Null Hypothesis is that:\n",
    "     - There is **_no difference in mean_** for all houses in Brooklyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Null Hypothesis? \n",
    "***\n",
    " - The purpose of a hypothesis test is to determine whether the null hypothesis is likely to be true given sample data.\n",
    " - If there is little evidence against the null hypothesis given the data, you accept the null hypothesis.\n",
    " - If the null hypothesis is unlikely given the data, you might reject the null in favor of the alternative hypothesis: that something interesting is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Alternative Hypothesis\n",
    "***\n",
    " - This is nothing but the question you ask which kind of \"opposes\" the Null Hypothesis\n",
    " \n",
    " - Therefore, in John's case the Alternative Hypothesis is that:\n",
    "     - \"The Mean of House Prices in OldTown **IS** different from the Houses all over Brooklyn\n",
    "     \n",
    " - Only 1 Hypothesis can be right\n",
    " \n",
    " - In hypothesis testing we test a sample, with the goal of accepting or rejecting a null hypothesis which is our assumption or the default position. The test tells us whether or not our primary hypothesis is true.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important\n",
    "***\n",
    "\n",
    "### The null hypothesis is assumed true and statistical evidence is required to reject it in favor of a research or alternative hypothesis\n",
    "\n",
    " - We require a standard on the available evidence to reject the null hypothesis (convict)\n",
    "\n",
    "\n",
    "If we set a low standard\n",
    ", then we would increase the percentage of innocent people convicted\n",
    "; however we would also increase the percentage of guilty people convicted\n",
    "(correctly rejecting the null)\n",
    "\n",
    "\n",
    "If we set a high standard, then we increase the the percentage of innocent people let free\n",
    " while we would also increase the percentage of guilty people let free\n",
    "(type II errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Math behind Hypothesis Testing (1/2)\n",
    "***\n",
    "Once you have the null and alternative hypothesis in hand, you choose a significance level (often denoted by the Greek letter α). \n",
    "\n",
    " - The significance level is a probability threshold that determines when you reject the null hypothesis.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Math behind Hypothesis Testing (2/2)\n",
    "***\n",
    "- So we use this to calculate a \"Test Statistic\" that would further help us do further calculations\n",
    " ***\n",
    " <center><img src=\"../images/hyp1.png\" alt=\"Drawing\" style=\"width: 350px;\"/></center> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Math behind Hypothesis Testing \n",
    "***\n",
    " - After carrying out a test, if the probability of getting a result as extreme as the one you observe due to chance is lower than the significance level, you reject the null hypothesis in favor of the alternative. \n",
    " \n",
    " - This probability of seeing a result as extreme or more extreme than the one observed is known as the *p-value*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpretation of p-value - EASY! (1/2)\n",
    "***\n",
    "- The p-value is really not as complicated as people make it sound\n",
    "\n",
    "- So now say that we have put a significance (alpha) = 0.05\n",
    "    - This means that if we see a p-value of lesser than 0.05, we reject our Null and accept the Alternative to be true \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of p-value - EASY! (2/2)\n",
    "***\n",
    "\n",
    "- What you have to understand is the data from your Null hypothesis follows a distribution (Normally distributed) \n",
    "     - Just imagine 1 bell curve of the data from the Null Hypothesis\n",
    "     - Now imagine another bell curve which hypothetically defines your Alternative Hypothesis\n",
    "     \n",
    "     See below: \n",
    "        \n",
    " ***\n",
    " <center><img src=\"../images/pval1.png\" alt=\"Drawing\" style=\"width: 350px;\"/></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpretation of p-value - EASY! (1/2)\n",
    "***\n",
    " - So what the p-value says is that it is the Probability of finding the Alternative Hypothesis data in the Null Hypothesis data (bell curve 1!!) \n",
    " \n",
    " - If it is lesser than 0.05(our threshold) then we reject it\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretation of p-value - EASY! (2/2)\n",
    "***\n",
    "Why reject it though? \n",
    "\n",
    " - BECAUSE OUR ALTERNATIVE HYPOTHESIS DATA IS REAL! NO ONE MADE IT UP! IT IS LEGIT DATA THAT IS OBSERVED AND NOT JUST FAKE! \n",
    " - So if it is real, we can say that such data isn't really described by the Null Hypothesis (Bell Curve 1) therefore the Null must be rejected as being TRUE! \n",
    " \n",
    " - It now makes sense! P-values are cool again "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Well....\n",
    "\n",
    " ***\n",
    " <center><img src=\"../images/panda_p_value.jpg\" alt=\"Drawing\" style=\"width: 350px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming back to John \n",
    "***\n",
    " - Let's see how John did now\n",
    " - Are house prices in OldTown really different from the House Prices of Brooklyn? \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ztest\n",
    "z_statistic, p_value = ztest(x1=data[data['Neighborhood'] == 'OldTown']['SalePrice'], value=data['SalePrice'].mean())\n",
    "print('Z-statistic is :{}'.format(z_statistic))\n",
    "print('P-value is :{}'.format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary of the p-value\n",
    "***\n",
    "* When performing a hypothesis test, the p-value is the probability of given or more extreme outcome given the null-hypothesis is true.\n",
    "\n",
    "* We see that the p-value is close to zero i.e., the probability of getting the given distribution of houseprices in OldTown under the assumption that it its mean is the same as the mean of all house prices.\n",
    "* So what can we infer from the p-value of our test? What should be the p-value beyond which we reject the null hypothesis.\n",
    "* The p-value below which we reject our hypothesis depends on our **significance level** $\\alpha$\n",
    "* For a 95% signifigance level we reject our null hypothesis if p-value is below 0.05\n",
    "* In this case we can reject the null hypothesis at 95% significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Another way to test: Gosset's (Student's) t-test\n",
    "***\n",
    "* The T-test is a statistical test used to determine whether a numeric data sample of differs significantly from the population or whether two samples differ from one another.\n",
    "* A z-test assumes a sample size >30 to work, but what if our sample is less than 30?\n",
    "* A t-test solves this problem and gives us a way to do a hypothesis test on a smaller sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Oh John\n",
    "***\n",
    "- Now, John also wants to see if house prices in `Stone Brook` neighborhood are different from the rest of the Houses in Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('No of houses in Stone Brook: {}'\\\n",
    "      .format(data['Neighborhood'].value_counts()['StoneBr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets do a t-test to test our hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_1samp(a= data[data['Neighborhood'] == 'StoneBr']['SalePrice'],               # Sample data\n",
    "                 popmean= data['SalePrice'].mean())  # Pop mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The p-value in this case again is low and we can reject our null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Type I and Type II Error\n",
    "***\n",
    "* If we again think of hypothesis test as a criminal trial then it makes sense to frame the verdict in terms of null and alternate hypothesis:\n",
    "\n",
    "![Trial](../images/jury.png)\n",
    "    * Null Hypothesis: Defendant is innocent\n",
    "    * Alternate Hypothesis: Defendant is guilty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Type I and Type II Error\n",
    "***\n",
    "* What type of error is being committed in the following circumstances?\n",
    "    * Declaring the defendant guilty when they are actually innocent?\n",
    "    * Declaring the defendant innocent when they are actually guilty?\n",
    "    \n",
    "* The first one is a type I error also known as a \"false positive\" or \"false hit\".\n",
    "* The type 1 error rate is equal to the significance level α, so setting a higher confidence level (and therefore lower alpha) reduces the chances of getting a false positive.\n",
    "\n",
    "* The second one is a type I error also known as a \"false negative\" or \"miss\". The higher your confidence level, the more likely you are to make a type II error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ***\n",
    " <center><img src=\"../images/hyp2.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ***\n",
    " <center><img src=\"../images/hyp3.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Type 1 Error \n",
    "***\n",
    "Type I error describes a situation where you reject the null hypothesis when it is actually true. \n",
    "\n",
    "This type of error is also known as a false positive or false hit.\n",
    "\n",
    "The type 1 error rate is equal to the significance level α, so setting a higher confidence level (and therefore lower alpha) reduces the chances of getting a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Type 2 error\n",
    "***\n",
    "Type II error describes a situation where you fail to reject the null hypothesis when it is actually false. \n",
    "\n",
    "Type II error is also known as a false negative or miss. The higher your confidence level, the more likely you are to make a type II error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Chi-Squared Goodness-Of-Fit Test (1/2)\n",
    "***\n",
    "A chi-squared goodness of fit tests whether the distribution of sample categorical data matches an expected distribution. \n",
    "\n",
    "* For example, you could use a chi-squared goodness-of-fit test to check whether the race demographics of members at your church or school match that of the entire U.S. population or whether the computer browser preferences of your friends match those of Internet uses as a whole.\n",
    "\n",
    "When working with categorical data the values the observations themselves aren't of much use for statistical testing because categories like \"male\", \"female,\" and \"other\" have no mathematical meaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Chi-Squared Goodness-Of-Fit Test (2/2)\n",
    "***\n",
    "Tests dealing with categorical variables are based on variable counts instead of the actual value of the variables themselves.\n",
    "\n",
    "Let's generate some fake demographic data for U.S. and Minnesota and walk through the chi-square goodness of fit test to check whether they are different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National\n",
      "col_0      count\n",
      "0               \n",
      "asian      15000\n",
      "black      50000\n",
      "hispanic   60000\n",
      "other      35000\n",
      "white     100000\n",
      " \n",
      "Minnesota\n",
      "col_0     count\n",
      "0              \n",
      "asian        75\n",
      "black       250\n",
      "hispanic    300\n",
      "other       150\n",
      "white       600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "national = pd.DataFrame([\"white\"]*100000 + [\"hispanic\"]*60000 +\\\n",
    "                        [\"black\"]*50000 + [\"asian\"]*15000 + [\"other\"]*35000)          \n",
    "\n",
    "minnesota = pd.DataFrame([\"white\"]*600 + [\"hispanic\"]*300 + \\\n",
    "                         [\"black\"]*250 +[\"asian\"]*75 + [\"other\"]*150)\n",
    "\n",
    "national_table = pd.crosstab(index=national[0], columns=\"count\")\n",
    "minnesota_table = pd.crosstab(index=minnesota[0], columns=\"count\")\n",
    "\n",
    "print( \"National\")\n",
    "print(national_table)\n",
    "print(\" \")\n",
    "print( \"Minnesota\")\n",
    "print(minnesota_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Chi-squared tests are based on the so-called chi-squared statistic. You calculate the chi-squared statistic with the following formula:\n",
    "\n",
    ">$sum((observed−expected)^2/expected)$\n",
    "\n",
    "\n",
    "In the formula, observed is the actual observed count for each category and expected is the expected count based on the distribution of the population for the corresponding category. \n",
    "\n",
    "Let's calculate the chi-squared statistic for our data to illustrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0\n",
      "count    18.194805\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "observed = minnesota_table\n",
    "\n",
    "national_ratios = national_table/len(national)  # Get population ratios\n",
    "\n",
    "expected = national_ratios * len(minnesota)   # Get expected counts\n",
    "\n",
    "chi_squared_stat = (((observed-expected)**2)/expected).sum()\n",
    "\n",
    "print(chi_squared_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note:** The chi-squared test assumes none of the expected counts are less than 5.\n",
    "\n",
    "Similar to the t-test where we compared the t-test statistic to a critical value based on the t-distribution to determine whether the result is significant, in the chi-square test we compare the chi-square test statistic to a critical value based on the chi-square distribution. \n",
    "\n",
    "The scipy library shorthand for the chi-square distribution is chi2. \n",
    "\n",
    "Let's use this knowledge to find the critical value for 95% confidence level and check the p-value of our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value\n",
      "9.487729036781154\n",
      "P value\n",
      "[0.00113047]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "crit = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*\n",
    "                      df = 4)   # Df = number of variable categories - 1\n",
    "\n",
    "print(\"Critical value\")\n",
    "print(crit)\n",
    "\n",
    "p_value = 1 - stats.chi2.cdf(x=chi_squared_stat,  # Find the p-value\n",
    "                             df=4)\n",
    "print(\"P value\")\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note:** we are only interested in the right tail of the chi-square distribution. Read more on this [here](https://en.wikipedia.org/wiki/Chi-squared_distribution).\n",
    "\n",
    "Since our chi-squared statistic exceeds the critical value, we'd reject the null hypothesis that the two distributions are the same.\n",
    "\n",
    "You can carry out a chi-squared goodness-of-fit test automatically using the scipy function scipy.stats.chisquare():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=array([18.19480519]), pvalue=array([0.00113047]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(f_obs= observed,   # Array of observed counts\n",
    "                f_exp= expected)   # Array of expected counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The test results agree with the values we calculated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Chi-Squared Test of Independence\n",
    "***\n",
    "Independence is a key concept in probability that describes a situation where knowing the value of one variable tells you nothing about the value of another. \n",
    "\n",
    "For instance, the month you were born probably doesn't tell you anything which web browser you use, so we'd expect birth month and browser preference to be independent. \n",
    "\n",
    "On the other hand, your month of birth might be related to whether you excelled at sports in school, so month of birth and sports performance might not be independent.\n",
    "\n",
    "The chi-squared test of independence tests whether two categorical variables are independent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John's final experiments\n",
    "***\n",
    "John wants to test if knowing `LandContour` which is the overall flatness of the property tells him anything about the price\n",
    "\n",
    " -  He has divided the `SalePrice` in three buckets - High, medium, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sp\n",
    "def compute_freq_chi2(x,y):\n",
    "    \"\"\"This function will compute frequency table of x an y\n",
    "    Pandas Series, and use the table to feed for the contigency table\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    x,y : Pandas Series, must be same shape for frequency table\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    None. But prints out frequency table, chi2 test statistic, and \n",
    "    p-value\n",
    "    \"\"\"\n",
    "    freqtab = pd.crosstab(x,y)\n",
    "    print(\"Frequency table\")\n",
    "    print(\"============================\")\n",
    "    print(freqtab)\n",
    "    print(\"============================\")\n",
    "    chi2,pval,dof,expected = sp.chi2_contingency(freqtab)\n",
    "    print(\"ChiSquare test statistic: \",chi2)\n",
    "    print(\"p-value: \",pval)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "price = pd.qcut(data['SalePrice'], 3, labels = ['High', 'Medium', 'Low'])\n",
    "compute_freq_chi2(data.LandContour, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The low p-value tells us that the two variables aren't independent and knowing the `LandContour` of a house does tells us something about its `SalePrice`.\n",
    "* The frequency distribution reflects this.\n",
    "* Houses that are Near Flat/Level(Lvl) have an equal distribution of `SalePrice`.\n",
    "* On the other hand houses that are at a Hillside i.e., Significant slope from side to side (HLS) have almost thrice as much houses with low price than high prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# In-session Recap Time\n",
    "***\n",
    "* Basic Probability Intuition\n",
    "* Conditional Probability\n",
    "* Normal Distribution and Standard Deviation\n",
    "* Z-Score & Central Limit Theorem\n",
    "* Confidence Intervals\n",
    "* Hyothesis Testing\n",
    "* Type 1 & Type 2 error\n",
    "* Chi-Squared Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Post Reads\n",
    "***\n",
    "* [A more mathematical treatment of probability theory for adventurous students](http://www.sci.utah.edu/~gerig/CS6640-F2010/prob-tut.pdf)\n",
    "* [The Central Limit Theorem {Clear Statistics}](https://medium.com/@chelseaparlett/the-central-limit-theorem-clear-statistics-278b80fd6f9f)\n",
    "* [Central Limit Theorem at work](https://medium.com/@mtterribile/central-limit-theorem-at-work-a0de13df37dc)\n",
    "* [Blackjack Simulations and the Central Limit Theorem](https://medium.com/@andrewadelson/using-monte-carlo-to-answer-a-blackjack-question-part-2-827260ddd2b8)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
